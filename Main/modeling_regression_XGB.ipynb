{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ XGBoost Regression: DAT Binding Prediction\n",
        "\n",
        "**Goal**: Predict pKi values (binding strength) using XGBoost with train/test split\n",
        "\n",
        "**Dataset**: 541 compounds with RDKit descriptors  \n",
        "**Target**: pKi (continuous variable)  \n",
        "**Method**: XGBoost Regression + 80/20 Train/Test Split + Early Stopping\n",
        "\n",
        "**Key Differences from Random Forest:**\n",
        "- Uses gradient boosting (sequential trees) instead of bagging\n",
        "- 80/20 split for proper test set evaluation\n",
        "- Early stopping to prevent overfitting\n",
        "- More hyperparameters to tune\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÇ Step 1: Load Processed Data from Analysis\n",
        "\n",
        "**Source:** `processed_DAT_rdkit_features.csv` (from dataanalyse.ipynb)\n",
        "\n",
        "This ensures we use the **same RDKit features** across all models!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed RDKit features from data analysis\n",
        "df_rdkit = pd.read_csv('processed_DAT_rdkit_features.csv')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìÇ LOADED PROCESSED DATA FROM ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"‚úÖ Dataset: {len(df_rdkit)} compounds\")\n",
        "print(f\"‚úÖ Features: {len(df_rdkit.columns)-2} RDKit descriptors\")\n",
        "print(f\"‚úÖ Source: dataanalyse.ipynb (same features as other models!)\")\n",
        "print(f\"\\nüìä pKi distribution:\")\n",
        "print(f\"   Min: {df_rdkit['pKi'].min():.2f}\")\n",
        "print(f\"   Max: {df_rdkit['pKi'].max():.2f}\")\n",
        "print(f\"   Mean: {df_rdkit['pKi'].mean():.2f}\")\n",
        "print(f\"   Median: {df_rdkit['pKi'].median():.2f}\")\n",
        "print(\"\\nüî¨ Available features:\")\n",
        "print([col for col in df_rdkit.columns if col not in ['ChEMBL_ID', 'pKi']])\n",
        "print(\"=\"*60)\n",
        "print(df_rdkit.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Step 2: Prepare Features & Split Data (80/20)\n",
        "\n",
        "**Key Difference from RF:** We use an 80/20 train/test split instead of cross-validation only.\n",
        "\n",
        "This allows:\n",
        "- Proper held-out test set evaluation\n",
        "- Early stopping monitoring\n",
        "- Fair comparison with Neural Networks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_rdkit.drop(['ChEMBL_ID', 'pKi'], axis=1)\n",
        "y = df_rdkit['pKi']\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üîß FEATURE PREPARATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "print(f\"\\nFeature names: {list(X.columns)}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 80/20 Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä TRAIN-TEST SPLIT (80/20)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training set: {X_train.shape[0]} compounds ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"Test set: {X_test.shape[0]} compounds ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nTraining pKi range: {y_train.min():.2f} - {y_train.max():.2f}\")\n",
        "print(f\"Test pKi range: {y_test.min():.2f} - {y_test.max():.2f}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features (important for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Features scaled using StandardScaler\")\n",
        "print(f\"   Training set scaled: {X_train_scaled.shape}\")\n",
        "print(f\"   Test set scaled: {X_test_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 3: Train Baseline XGBoost Model\n",
        "\n",
        "**Baseline Configuration:**\n",
        "- `n_estimators=1000` (will use early stopping)\n",
        "- `learning_rate=0.1` (default)\n",
        "- `max_depth=6` (default)\n",
        "- Early stopping with 50 rounds patience\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize baseline XGBoost model\n",
        "xgb_baseline = XGBRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"üöÄ Training Baseline XGBoost Model with Early Stopping...\")\n",
        "print(\"   This may take a minute...\\n\")\n",
        "\n",
        "# Train with early stopping\n",
        "xgb_baseline.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    eval_set=[(X_test_scaled, y_test)],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Training completed!\")\n",
        "print(f\"   Best iteration: {xgb_baseline.best_iteration}\")\n",
        "print(f\"   Total trees trained: {xgb_baseline.n_estimators}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 4: Evaluate Baseline Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predictions on training set\n",
        "y_train_pred = xgb_baseline.predict(X_train_scaled)\n",
        "\n",
        "# Predictions on test set\n",
        "y_test_pred = xgb_baseline.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìä BASELINE XGBOOST MODEL PERFORMANCE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'Metric':<20} {'Training Set':<20} {'Test Set':<20}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'R¬≤ Score':<20} {train_r2:<20.4f} {test_r2:<20.4f}\")\n",
        "print(f\"{'RMSE':<20} {train_rmse:<20.4f} {test_rmse:<20.4f}\")\n",
        "print(f\"{'MAE':<20} {train_mae:<20.4f} {test_mae:<20.4f}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Check for overfitting\n",
        "overfit_r2 = train_r2 - test_r2\n",
        "print(f\"\\nüîç Overfitting Analysis:\")\n",
        "print(f\"   R¬≤ difference (train - test): {overfit_r2:.4f}\")\n",
        "if overfit_r2 > 0.1:\n",
        "    print(f\"   ‚ö†Ô∏è  Potential overfitting detected!\")\n",
        "elif overfit_r2 > 0.05:\n",
        "    print(f\"   ‚ö° Mild overfitting\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Good generalization!\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Step 5: Visualize Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual vs Predicted plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Training set\n",
        "axes[0].scatter(y_train, y_train_pred, alpha=0.6, edgecolors='black', s=50)\n",
        "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
        "             'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0].set_xlabel('Actual pKi', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Predicted pKi', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title(f'Training Set (n={len(y_train)})\\nR¬≤ = {train_r2:.4f}, RMSE = {train_rmse:.4f}', \n",
        "                  fontsize=13, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Test set\n",
        "axes[1].scatter(y_test, y_test_pred, alpha=0.6, edgecolors='black', s=50, color='orange')\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
        "             'r--', lw=2, label='Perfect Prediction')\n",
        "axes[1].set_xlabel('Actual pKi', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Predicted pKi', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title(f'Test Set (n={len(y_test)})\\nR¬≤ = {test_r2:.4f}, RMSE = {test_rmse:.4f}', \n",
        "                  fontsize=13, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Residual plots\n",
        "train_residuals = y_train - y_train_pred\n",
        "test_residuals = y_test - y_test_pred\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Training residuals\n",
        "axes[0].scatter(y_train_pred, train_residuals, alpha=0.6, edgecolors='black', s=50)\n",
        "axes[0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[0].set_xlabel('Predicted pKi', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Residuals (Actual - Predicted)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Training Set Residuals', fontsize=13, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Test residuals\n",
        "axes[1].scatter(y_test_pred, test_residuals, alpha=0.6, edgecolors='black', s=50, color='orange')\n",
        "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[1].set_xlabel('Predicted pKi', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Residuals (Actual - Predicted)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Test Set Residuals', fontsize=13, fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 6: Feature Importance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': xgb_baseline.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üéØ FEATURE IMPORTANCE (Baseline XGBoost)\")\n",
        "print(\"=\"*60)\n",
        "print(feature_importance.to_string(index=False))\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['Feature'], feature_importance['Importance'], \n",
        "         color='steelblue', edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
        "plt.title('Feature Importance - Baseline XGBoost Model', fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Step 7: Hyperparameter Tuning with RandomizedSearchCV\n",
        "\n",
        "**Strategy:** Use RandomizedSearch to find optimal hyperparameters\n",
        "\n",
        "**Key Parameters to Tune:**\n",
        "- `n_estimators`: Number of boosting rounds\n",
        "- `learning_rate`: Step size for updates\n",
        "- `max_depth`: Tree complexity\n",
        "- `subsample`: Row sampling\n",
        "- `colsample_bytree`: Column sampling\n",
        "- `gamma`: Minimum loss reduction for split\n",
        "- `reg_alpha`: L1 regularization\n",
        "- `reg_lambda`: L2 regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameter distributions\n",
        "param_distributions = {\n",
        "    'n_estimators': randint(100, 1000),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'min_child_weight': randint(1, 7),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'gamma': uniform(0, 0.5),\n",
        "    'reg_alpha': uniform(0, 1),\n",
        "    'reg_lambda': uniform(0, 2)\n",
        "}\n",
        "\n",
        "# Initialize XGBoost for tuning\n",
        "xgb_tuning = XGBRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_tuning,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=100,\n",
        "    scoring='r2',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîç HYPERPARAMETER TUNING - RANDOMIZED SEARCH\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total iterations: 100\")\n",
        "print(f\"Cross-validation: 5-fold\")\n",
        "print(f\"Scoring metric: R¬≤\")\n",
        "print(f\"\\nüöÄ Starting search... (this will take several minutes)\\n\")\n",
        "\n",
        "# Fit\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ HYPERPARAMETER TUNING COMPLETED!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nüèÜ Best Parameters:\")\n",
        "for param, value in random_search.best_params_.items():\n",
        "    print(f\"   {param:<20s}: {value}\")\n",
        "print(f\"\\nüéØ Best Cross-Validation R¬≤ Score: {random_search.best_score_:.4f}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get best model\n",
        "best_xgb_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "y_train_pred_tuned = best_xgb_model.predict(X_train_scaled)\n",
        "y_test_pred_tuned = best_xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "train_r2_tuned = r2_score(y_train, y_train_pred_tuned)\n",
        "train_rmse_tuned = np.sqrt(mean_squared_error(y_train, y_train_pred_tuned))\n",
        "train_mae_tuned = mean_absolute_error(y_train, y_train_pred_tuned)\n",
        "\n",
        "test_r2_tuned = r2_score(y_test, y_test_pred_tuned)\n",
        "test_rmse_tuned = np.sqrt(mean_squared_error(y_test, y_test_pred_tuned))\n",
        "test_mae_tuned = mean_absolute_error(y_test, y_test_pred_tuned)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìä TUNED XGBOOST MODEL PERFORMANCE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'Metric':<20} {'Training Set':<20} {'Test Set':<20}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'R¬≤ Score':<20} {train_r2_tuned:<20.4f} {test_r2_tuned:<20.4f}\")\n",
        "print(f\"{'RMSE':<20} {train_rmse_tuned:<20.4f} {test_rmse_tuned:<20.4f}\")\n",
        "print(f\"{'MAE':<20} {train_mae_tuned:<20.4f} {test_mae_tuned:<20.4f}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Check for overfitting\n",
        "overfit_r2_tuned = train_r2_tuned - test_r2_tuned\n",
        "print(f\"\\nüîç Overfitting Analysis:\")\n",
        "print(f\"   R¬≤ difference (train - test): {overfit_r2_tuned:.4f}\")\n",
        "if overfit_r2_tuned > 0.1:\n",
        "    print(f\"   ‚ö†Ô∏è  Potential overfitting detected!\")\n",
        "elif overfit_r2_tuned > 0.05:\n",
        "    print(f\"   ‚ö° Mild overfitting\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Good generalization!\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 8: Compare Baseline vs Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Baseline XGBoost', 'Tuned XGBoost'],\n",
        "    'Train R¬≤': [train_r2, train_r2_tuned],\n",
        "    'Test R¬≤': [test_r2, test_r2_tuned],\n",
        "    'Train RMSE': [train_rmse, train_rmse_tuned],\n",
        "    'Test RMSE': [test_rmse, test_rmse_tuned],\n",
        "    'Train MAE': [train_mae, train_mae_tuned],\n",
        "    'Test MAE': [test_mae, test_mae_tuned]\n",
        "})\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üìä MODEL COMPARISON: Baseline vs Tuned\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate improvements\n",
        "r2_improvement = (test_r2_tuned - test_r2) / abs(test_r2) * 100 if test_r2 != 0 else 0\n",
        "rmse_improvement = (test_rmse - test_rmse_tuned) / test_rmse * 100 if test_rmse != 0 else 0\n",
        "mae_improvement = (test_mae - test_mae_tuned) / test_mae * 100 if test_mae != 0 else 0\n",
        "\n",
        "print(f\"\\n‚ú® Improvements on Test Set:\")\n",
        "print(f\"   R¬≤ improvement: {r2_improvement:+.2f}%\")\n",
        "print(f\"   RMSE improvement: {rmse_improvement:+.2f}%\")\n",
        "print(f\"   MAE improvement: {mae_improvement:+.2f}%\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "metrics = ['R¬≤', 'RMSE', 'MAE']\n",
        "baseline_vals = [test_r2, test_rmse, test_mae]\n",
        "tuned_vals = [test_r2_tuned, test_rmse_tuned, test_mae_tuned]\n",
        "\n",
        "for i, (metric, baseline, tuned) in enumerate(zip(metrics, baseline_vals, tuned_vals)):\n",
        "    x = ['Baseline', 'Tuned']\n",
        "    y = [baseline, tuned]\n",
        "    colors = ['steelblue', 'forestgreen']\n",
        "    \n",
        "    bars = axes[i].bar(x, y, color=colors, edgecolor='black', alpha=0.7)\n",
        "    axes[i].set_ylabel(metric, fontsize=12, fontweight='bold')\n",
        "    axes[i].set_title(f'{metric} Comparison (Test Set)', fontsize=13, fontweight='bold')\n",
        "    axes[i].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[i].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.4f}',\n",
        "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 9: Classification Performance (Confusion Matrix)\n",
        "\n",
        "Convert continuous predictions to categories:\n",
        "- **Low**: pKi < 6.0\n",
        "- **Medium**: 6.0 ‚â§ pKi < 8.0\n",
        "- **High**: pKi ‚â• 8.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define classification function\n",
        "def classify_pKi(pKi_values):\n",
        "    \"\"\"Convert continuous pKi to categories\"\"\"\n",
        "    categories = []\n",
        "    for pKi in pKi_values:\n",
        "        if pKi < 6.0:\n",
        "            categories.append('Low')\n",
        "        elif pKi < 8.0:\n",
        "            categories.append('Medium')\n",
        "        else:\n",
        "            categories.append('High')\n",
        "    return np.array(categories)\n",
        "\n",
        "# Convert to categories (test set only)\n",
        "y_test_categorical = classify_pKi(y_test)\n",
        "y_test_pred_baseline_cat = classify_pKi(y_test_pred)\n",
        "y_test_pred_tuned_cat = classify_pKi(y_test_pred_tuned)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä TEST SET CLASSIFICATION DISTRIBUTION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Low Binders (pKi < 6.0): {np.sum(y_test_categorical == 'Low')} compounds\")\n",
        "print(f\"Medium Binders (6.0 ‚â§ pKi < 8.0): {np.sum(y_test_categorical == 'Medium')} compounds\")\n",
        "print(f\"High Binders (pKi ‚â• 8.0): {np.sum(y_test_categorical == 'High')} compounds\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrices\n",
        "cm_baseline = confusion_matrix(y_test_categorical, y_test_pred_baseline_cat, labels=['Low', 'Medium', 'High'])\n",
        "cm_tuned = confusion_matrix(y_test_categorical, y_test_pred_tuned_cat, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Side-by-side confusion matrix comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Baseline confusion matrix\n",
        "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=['Low', 'Medium', 'High'],\n",
        "            yticklabels=['Low', 'Medium', 'High'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "axes[0].set_xlabel('Predicted Category', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Actual Category', fontsize=12, fontweight='bold')\n",
        "baseline_acc = np.trace(cm_baseline) / cm_baseline.sum() * 100\n",
        "axes[0].set_title(f'Baseline XGBoost - Test Set\\nAccuracy: {baseline_acc:.2f}%', \n",
        "                  fontsize=13, fontweight='bold')\n",
        "\n",
        "# Tuned confusion matrix\n",
        "sns.heatmap(cm_tuned, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
        "            xticklabels=['Low', 'Medium', 'High'],\n",
        "            yticklabels=['Low', 'Medium', 'High'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "axes[1].set_xlabel('Predicted Category', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Actual Category', fontsize=12, fontweight='bold')\n",
        "tuned_acc = np.trace(cm_tuned) / cm_tuned.sum() * 100\n",
        "axes[1].set_title(f'Tuned XGBoost - Test Set\\nAccuracy: {tuned_acc:.2f}%', \n",
        "                  fontsize=13, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä CLASSIFICATION REPORTS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nüîµ Baseline XGBoost:\")\n",
        "print(classification_report(y_test_categorical, y_test_pred_baseline_cat, labels=['Low', 'Medium', 'High']))\n",
        "print(\"\\nüü¢ Tuned XGBoost:\")\n",
        "print(classification_report(y_test_categorical, y_test_pred_tuned_cat, labels=['Low', 'Medium', 'High']))\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 10: Final Summary & Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"üéØ FINAL SUMMARY - XGBOOST REGRESSION (NO PCA)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä Dataset:\")\n",
        "print(f\"   Total compounds: {len(df_rdkit)}\")\n",
        "print(f\"   Training set: {len(X_train)} (80%)\")\n",
        "print(f\"   Test set: {len(X_test)} (20%)\")\n",
        "print(f\"   Features: {X.shape[1]} RDKit descriptors (no PCA)\")\n",
        "\n",
        "print(f\"\\nüèÜ Best Model Performance (Test Set):\") \n",
        "print(f\"   R¬≤ Score: {test_r2_tuned:.4f}\")\n",
        "print(f\"   RMSE: {test_rmse_tuned:.4f}\")\n",
        "print(f\"   MAE: {test_mae_tuned:.4f}\")\n",
        "print(f\"   Classification Accuracy: {tuned_acc:.2f}%\")\n",
        "\n",
        "print(f\"\\n‚ú® Improvements from Tuning:\")\n",
        "print(f\"   R¬≤ improvement: {r2_improvement:+.2f}%\")\n",
        "print(f\"   RMSE improvement: {rmse_improvement:+.2f}%\")\n",
        "print(f\"   MAE improvement: {mae_improvement:+.2f}%\")\n",
        "\n",
        "print(f\"\\nüîç Top 3 Most Important Features:\")\n",
        "for i in range(min(3, len(feature_importance))):\n",
        "    feat = feature_importance.iloc[i]\n",
        "    print(f\"   {i+1}. {feat['Feature']}: {feat['Importance']:.4f}\")\n",
        "\n",
        "print(f\"\\nüí° Key Insights:\")\n",
        "print(f\"   ‚Ä¢ XGBoost with 80/20 split allows proper test set evaluation\")\n",
        "print(f\"   ‚Ä¢ Early stopping prevents overfitting\")\n",
        "print(f\"   ‚Ä¢ Hyperparameter tuning {'improved' if r2_improvement > 0 else 'maintained'} performance\")\n",
        "print(f\"   ‚Ä¢ Model generalizes {'well' if overfit_r2_tuned < 0.05 else 'reasonably'} to unseen data\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ Analysis Complete!\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
